# SteamID Crawler
AWS Lambda function that cralws the Steam API for all gamers' Steam IDs, storing the data into DynamoDB. I use the ISteamUser GetPlayerSummaries endpoint because it allows me to search for 100 users per request, the most out of any endpoint in the Steam API.

## Steam Countries
Steam country, state and city codes are specific to Steam and are not human readable. I use the [data](https://github.com/Holek/steam-friends-countries) made available by <b>[@Holek](https://github.com/Holek)</b> to convert it into a more useful format. The license for it available [here](./steam_countries_license.txt).

## FAQ
### What is the purpose of this project?
This is the first step in a larger project that provides a bunch of video game statistics. A bunch of Steam endpoints require a user's SteamID to work. I want to use these endpoints, so I created this project to get me all the SteamIds.
### Why is there almost no error handling?
It was a concious decision not to catch errors or rejected promises in the code. Failures are better hangled through the AWS configuration than at the code level. Future crawler invocations will retry the same failed steamId range, ensuring no data loss. Our key in DynamoDB ensures no duplicate items are created. On failure, I am notified through AWS SNS and the error is logged in CloudWatch Logs.

### Why do you store the Lambda state in the DB?
The code does have a state, but Lambda functions do not necessarily remember the state between invocations. The original implementation used a Redis instance in AWS ElastiCache to store the state between invocations. I changed this because it is easier for me to check the crawler's progress using the DynamoDB UI and because ElastiCache has a fixed monthly cost that is significantly higher than just using DynamoDB. The performance gain from Redis was not a concern for this project.

### Why are are some promises manually timed out?
On a successful execution, this code can take a long time to finish executing. The maximum timeout that a Lambda function can be configured to is 15 minutes. I did not want to wait the full duration just because of an AWS configuration error, which are bound to happen.

### What technologies are used by this crawler?
- Node.js v14.16.1 for the code
- JSDoc for documentation
- AWS DynamoDB for data and state storage
- ~~Redis for state storage~~ Not any more as of v2.0.0, see FAQ for reasons
- AWS Lambda function for the environment
- AWS SNS for failure notifications
- AWS EventBridge for Lambda invocations
- AWS VPC for internet access
- AWS IAM for security policies